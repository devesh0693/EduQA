version: '3.8'

services:
  # PostgreSQL Database with vector extension
  postgres:
    image: pgvector/pgvector:pg15
    container_name: qa_postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-qa_system}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-password123}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - qa_network

  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: qa_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - qa_network

  # Elasticsearch for full-text search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: qa_elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - cluster.name=qa-cluster
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    networks:
      - qa_network

  # Django Backend API
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: qa_backend
    environment:
      - DEBUG=${DEBUG:-False}
      - POSTGRES_DB=${POSTGRES_DB:-qa_system}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-password123}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - REDIS_URL=redis://redis:6379/0
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - SECRET_KEY=${SECRET_KEY:-your-secret-key-here}
      - ALLOWED_HOSTS=${ALLOWED_HOSTS:-localhost,127.0.0.1}
      - CORS_ALLOWED_ORIGINS=${CORS_ALLOWED_ORIGINS:-http://localhost:3000,http://127.0.0.1:3000}
    ports:
      - "8000:8000"
    volumes:
      - .:/app
      - media_files:/app/media
      - static_files:/app/staticfiles
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - qa_network
    command: >
      sh -c "
        python manage.py makemigrations &&
        python manage.py migrate &&
        python manage.py collectstatic --noinput &&
        gunicorn config.wsgi:application --bind 0.0.0.0:8000 --workers 4 --timeout 120 --access-logfile - --error-logfile -
      "

  # Frontend (React)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: qa_frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - REACT_APP_API_URL=${REACT_APP_API_URL:-http://localhost:8000/api}
      - NODE_ENV=${NODE_ENV:-development}
      - REACT_APP_ENVIRONMENT=${REACT_APP_ENVIRONMENT:-development}
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - qa_network

  # Nginx Reverse Proxy (for production)
  nginx:
    image: nginx:alpine
    container_name: qa_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - static_files:/var/www/static
      - media_files:/var/www/media
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - backend
      - frontend
    restart: unless-stopped
    networks:
      - qa_network
    profiles:
      - production

  # Prometheus for monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: qa_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - qa_network
    profiles:
      - monitoring

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: qa_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - qa_network
    profiles:
      - monitoring

  # Model Server (for ML inference)
  model_server:
    build:
      context: .
      dockerfile: Dockerfile.model
    container_name: qa_model_server
    environment:
      - MODEL_PATH=/app/models
      - BATCH_SIZE=${BATCH_SIZE:-8}
      - MAX_LENGTH=${MAX_LENGTH:-512}
      - PORT=8001
    ports:
      - "8001:8001"
    volumes:
      - ./ml_models:/app/models
      - model_cache:/root/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - gpu
    restart: unless-stopped
    networks:
      - qa_network

  # Celery Worker for background tasks
  celery_worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: qa_celery_worker
    environment:
      - DEBUG=${DEBUG:-False}
      - POSTGRES_DB=${POSTGRES_DB:-qa_system}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-password123}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    volumes:
      - .:/app
      - media_files:/app/media
    depends_on:
      - postgres
      - redis
    command: celery -A config worker --loglevel=info --concurrency=4
    restart: unless-stopped
    networks:
      - qa_network
    profiles:
      - production

  # Celery Beat for scheduled tasks
  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: qa_celery_beat
    environment:
      - DEBUG=${DEBUG:-False}
      - POSTGRES_DB=${POSTGRES_DB:-qa_system}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-password123}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    volumes:
      - .:/app
    depends_on:
      - postgres
      - redis
    command: celery -A config beat --loglevel=info
    restart: unless-stopped
    networks:
      - qa_network
    profiles:
      - production

volumes:
  postgres_data:
  elasticsearch_data:
  redis_data:
  media_files:
  static_files:
  model_cache:
  prometheus_data:
  grafana_data:

networks:
  qa_network:
    driver: bridge